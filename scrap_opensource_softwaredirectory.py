import requests,pandas as pd
from bs4 import BeautifulSoup
import json
url = 'https://opensourcesoftwaredirectory.com/Home-users'
html =requests.get(url,timeout=(3.05, 27))
soup = BeautifulSoup(html.text, 'html.parser')
category = soup.findAll('span', {'class': 'category_text'})
products=[]
for i in category:
	payload = {'category':i}
	url= 'https://opensourcesoftwaredirectory.com/home/getsubcategories/'
	re =requests.post(url,data=payload)
	stripped = list(map(str.strip, json.loads(re.text)))
	for item in stripped:
		link = "https://opensourcesoftwaredirectory.com/"+i.text.replace(" ","-")+"/"+item.replace(" ","-")
		htmls =requests.get(link,timeout=(3.05, 27))
		soups = BeautifulSoup(htmls.text, 'html.parser')
		apps = soups.findAll('a', {'class': 'app_url'})
		for app in apps:
			print(link, app.text)
			products.append([app.text,app['href']])

df_products= pd.DataFrame(products)
df_products.to_csv("opensourcesoftwaredirectory.csv")	

